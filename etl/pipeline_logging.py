import logging
from etl.transform import transform_data
from etl.load_to_db import load_to_db



# âœ… Logging config for Day 11
logging.basicConfig(
    filename="log/pipeline.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def run_pipeline_safe():
    try:
        logging.info("ğŸš€ Pipeline started")

        df = transform_data()
        logging.info(f"âœ… Data loaded â€” {df.shape[0]} rows")

        load_to_db(df)
        logging.info("âœ… load_to_db() completed")

        logging.info("ğŸ‰ Pipeline finished successfully")

    except Exception as e:
        logging.error(f"âŒ Pipeline failed: {e}")

if __name__ == "__main__":
    run_pipeline_safe()

